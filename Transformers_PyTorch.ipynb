{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4bltvTgPPqKk",
        "Oj2CKqE-P1Nm",
        "loFw1M9sYKOL",
        "lH07jyCBYSHh",
        "FAa_lDeKYf6Z",
        "1f0MrgA_ZVv1"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prithuls/Anomaly-Transformer/blob/main/Transformers_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Vision Transformer**"
      ],
      "metadata": {
        "id": "4bltvTgPPqKk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYel7sKheSZn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbed(nn.Module):\n",
        "    def __init__(self, img_size, patch_size, in_channels= 3, embed_dim= 768):\n",
        "        super().__init__()\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.n_patches = (img_size // patch_size) ** 2\n",
        "\n",
        "        self.proj = nn.Conv2d(\n",
        "            in_channels,\n",
        "            embed_dim,\n",
        "            kernel_size= patch_size,\n",
        "            stride= patch_size\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.proj(x) ## n_sample, embed_dim, patch_size, patch_size\n",
        "        x = x.flatten(2)\n",
        "        x = x.transpose(1, 2)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "txfkdPNG7xMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, n_heads= 12, qkv_bias= True, attn_p= 0., proj_p= 0.):\n",
        "        super().__init__()\n",
        "        self.n_heads = n_heads\n",
        "        self.dim = dim\n",
        "        self.head_dim = dim // n_heads\n",
        "        self.scale = self.head_dim ** (-0.5)\n",
        "\n",
        "        self.qkv = nn.Linear(dim, dim*3, bias= qkv_bias)\n",
        "        self.attn_drop = nn.Dropout(attn_p)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_p)\n",
        "\n",
        "    def forward(self, x):\n",
        "        n_samples, n_tokens, dim = x.shape\n",
        "        if dim != self.dim:\n",
        "            raise ValueError\n",
        "        qkv = self.qkv(x) ## n_samples, n_tokens, 3 * dim\n",
        "        qkv = qkv.reshape(\n",
        "            n_samples, n_tokens, 3, self.n_heads, self.head_dim\n",
        "        )\n",
        "        qkv = qkv.permute(\n",
        "            2, 0, 3, 1, 4\n",
        "        )   ## 3, n_samples, n_heads, n_tokens, head_dim\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] ## n_samples, n_heads, n_tokens, head_dim\n",
        "        k_t = k.transpose(-2, -1)\n",
        "\n",
        "        dp = (q @ k_t) * self.scale ## n_samples, n_heads, n_tokens, n_tokens\n",
        "        attn = dp.softmax(dim = -1) ## n_samples, n_heads, n_tokens, n_tokens\n",
        "        attn = self.attn_drop(attn) \n",
        "\n",
        "        weighted_avg = attn @ v ## n_samples, n_heads, n_tokens, head_dim\n",
        "        weighted_avg = weighted_avg.transpose(1, 2) ## n_samples, n_tokens, n_heads, head_dim\n",
        "\n",
        "        weighted_avg = weighted_avg.flatten(2) ## n_samples, n_tokens, dim\n",
        "        x = self.proj(weighted_avg)\n",
        "        x = self.proj_drop(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "jZ4HcwrNAfQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features, p= 0.):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
        "        self.act = nn.GELU()\n",
        "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
        "        self.drop = nn.Dropout(p)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Runs forward pass\n",
        "\n",
        "\n",
        "        Paremeters\n",
        "        ----------\n",
        "        x ## (n_samples, n_tokens, in_features)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Tensor ## (n_samples, n_tokens, out_features)\n",
        "        \n",
        "        \"\"\"\n",
        "        x = self.fc1(x) ## n_samples, n_tokens, hidden_features\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x) ## n_samples, n_tokens, out_features\n",
        "        x = self.drop(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "0e4YduLxwE3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module): \n",
        "    def __init__(self, dim, n_heads, mlp_ratio= 4.0, qkv_bias= True, p= 0., attn_p= 0.):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(dim, eps= 1e-6)\n",
        "        self.attn = Attention(\n",
        "            dim, \n",
        "            n_heads = n_heads, \n",
        "            qkv_bias = qkv_bias, \n",
        "            attn_p = attn_p, \n",
        "            proj_p = p\n",
        "        )\n",
        "        self.norm2 = nn.LayerNorm(dim, eps= 1e-6)\n",
        "        hidden_features = int(dim * mlp_ratio)\n",
        "        self.mlp = MLP(\n",
        "            in_features = dim,\n",
        "            hidden_features = hidden_features,\n",
        "            out_features = dim\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.norm1(x))\n",
        "        x = x + self.mlp(self.norm2(x))\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "O6U4n-QqAgrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VisionTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self, \n",
        "        img_size= 256,\n",
        "        patch_size= 16,\n",
        "        in_channels= 3,\n",
        "        n_classes= 1000,\n",
        "        embed_dim= 768,\n",
        "        depth= 12,\n",
        "        n_heads= 12,\n",
        "        mlp_ratio= 4,\n",
        "        qkv_bias= True,\n",
        "        p= 0,\n",
        "        attn_p= 0\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.patch_embed= PatchEmbed(\n",
        "            img_size= img_size,\n",
        "            patch_size= patch_size, \n",
        "            in_channels= in_channels, \n",
        "            embed_dim= embed_dim\n",
        "        )\n",
        "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "        self.pos_embed = nn.Parameter(\n",
        "            torch.zeros(1, 1 + self.patch_embed.n_patches, embed_dim)\n",
        "        )\n",
        "        self.pos_drop = nn.Dropout(p= p)\n",
        "        self.blocks = nn.ModuleList(\n",
        "            [\n",
        "                Block(\n",
        "                    dim= embed_dim, \n",
        "                    n_heads= n_heads, \n",
        "                    mlp_ratio= mlp_ratio, \n",
        "                    qkv_bias= qkv_bias, \n",
        "                    p= p, \n",
        "                    attn_p= attn_p\n",
        "                )\n",
        "                for _ in range(depth)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.norm = nn.LayerNorm(embed_dim, eps= 1e-6)\n",
        "        self.head = nn.Linear(embed_dim, n_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        n_samples = x.shape[0]\n",
        "        x = self.patch_embed(x)\n",
        "\n",
        "        cls_token = self.cls_token.expand(\n",
        "            n_samples, -1, -1 \n",
        "        )\n",
        "        x = torch.cat((cls_token, x), dim= 1)\n",
        "        x = x + self.pos_embed\n",
        "        x = self.pos_drop(x)\n",
        "\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        \n",
        "        x = self.norm(x)\n",
        "        cls_token_final = x[:,0]\n",
        "        x = self.head(cls_token_final)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "-d5RF5ywD_BF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "diWKZNcrP03v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Swin Transformer**"
      ],
      "metadata": {
        "id": "Oj2CKqE-P1Nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl-IUt3Fjk1F",
        "outputId": "07196986-bea5-40d7-bfdf-4923f877d35b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, einsum\n",
        "import numpy as np\n",
        "from einops import rearrange, repeat"
      ],
      "metadata": {
        "id": "0m7TOGjMP4uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## For shifting window\n",
        "\n",
        "class CyclicShift(nn.Module):\n",
        "    def __init__(self, displacement):\n",
        "        super().__init__()\n",
        "        self.displacement = displacement\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return torch.roll(x, shifts= (self.displacement, self.displacement), dims= (1, 2))\n",
        "\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(x, **kwargs) + x"
      ],
      "metadata": {
        "id": "5bSqUZFOQD59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, dim)\n",
        "        )  \n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "qk4zew_jQELi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## This helps with shifted windows\n",
        "\n",
        "def create_mask(window_size, displacement, upper_lower, left_right):\n",
        "    mask = torch.zeros(window_size ** 2, window_size ** 2)\n",
        "\n",
        "    if upper_lower:\n",
        "        mask[- displacement * window_size : , : - displacement * window_size] = float('-inf')\n",
        "        mask[: - displacement * window_size, - displacement * window_size : ] = float('-inf')\n",
        "\n",
        "    if left_right:\n",
        "        mask = rearrange(mask, '(h1 w1) (h2 w2) -> h1 w1 h2 w2',\n",
        "                                h1 = window_size, h2 = window_size)\n",
        "        mask[:, - displacement :, :, : - displacement] = float(\"-inf\")\n",
        "        mask[:, : - displacement, :, -displacement : ] = float(\"-inf\")\n",
        "        mask = rearrange(mask, 'h1 w1 h2 w2 -> (h1 w1) (h2 w2)')\n",
        "\n",
        "    return mask\n"
      ],
      "metadata": {
        "id": "7lbsSAkyQFbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## For distances between two patches / windows\n",
        "\n",
        "def get_relative_distances(window_size):\n",
        "    indices = torch.tensor(\n",
        "        np.array(\n",
        "            [[x, y] for x in range(window_size) for y in range(window_size)]\n",
        "        )\n",
        "    )\n",
        "    distances = indices[None, :, :] - indices[:, None, :]\n",
        "    return distances"
      ],
      "metadata": {
        "id": "LXUELtY9QFeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices = torch.tensor(\n",
        "      np.array(\n",
        "          [[x, y] for x in range(2) for y in range(2)]\n",
        "      )\n",
        "  )\n",
        "distances = indices[None, :, :] - indices[:, None, :]"
      ],
      "metadata": {
        "id": "ywLVUIBcmRXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WindowAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        heads,\n",
        "        head_dim,\n",
        "        shifted,\n",
        "        window_size,\n",
        "        relative_pos_embedding\n",
        "    ):\n",
        "        super().__init__()\n",
        "        inner_dim = head_dim * heads\n",
        "        self.heads = heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        self.window_size = window_size\n",
        "        self.relative_pos_embedding = relative_pos_embedding\n",
        "        self.shifted = shifted\n",
        "\n",
        "        if self.shifted:\n",
        "            displacement = window_size // 2\n",
        "            self.cyclic_shift = CyclicShift(-displacement)\n",
        "            self.cyclic_back_shift = CyclicShift(displacement)\n",
        "\n",
        "            self.upper_lower_mask = nn.Parameter(\n",
        "                create_mask(\n",
        "                    window_size = window_size,\n",
        "                    displacement = displacement,\n",
        "                    upper_lower = True,\n",
        "                    left_right = False\n",
        "                ), requires_grad= False\n",
        "            )\n",
        "\n",
        "            self.left_right_mask = nn.Parameter(\n",
        "                create_mask(\n",
        "                    window_size = window_size,\n",
        "                    displacement = displacement,\n",
        "                    upper_lower = False,\n",
        "                    left_right = True\n",
        "                ), requires_grad= False\n",
        "            )\n",
        "\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias= False)\n",
        "\n",
        "        if self.relative_pos_embedding:\n",
        "            self.relative_indices = get_relative_distances(window_size) + window_size - 1 ## Values get positive here\n",
        "            self.pos_embedding = nn.Parameter(\n",
        "                torch.randn(\n",
        "                    2 * window_size - 1, 2 * window_size - 1\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            self.pos_embedding = nn.Parameter(torch.randn(window_size ** 2, window_size ** 2))\n",
        "\n",
        "        self.to_out = nn.Linear(inner_dim, dim)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.shifted:\n",
        "            x = self.cyclic_shift(x)\n",
        "        \n",
        "        b, n_h, n_w, _, h = *x.shape, self.heads\n",
        "\n",
        "        qkv = self.to_qkv(x).chunk(3, dim= -1)\n",
        "        nw_h = n_h // self.window_size\n",
        "        nw_w = n_w // self.window_size\n",
        "\n",
        "        q, k, v = map(\n",
        "            lambda t: rearrange(t, 'b (nw_h w_h) (nw_w w_w) (h d) -> b h (nw_h nw_w) (w_h w_w) d',\n",
        "                                h = h, w_h = self.window_size, w_w = self.window_size,), qkv\n",
        "        )\n",
        "\n",
        "        dots = einsum('b h w i d, b h w j d -> b h w i j', q, k) * self.scale\n",
        "        if self.relative_pos_embedding:\n",
        "            dots += self.pos_embedding[self.relative_indices[:, :, 0], self.relative_indices[:, :, 1]]\n",
        "        else:\n",
        "            dots += self.pos_embedding\n",
        "\n",
        "        if self.shifted:\n",
        "            dots[:, :, -nw_w : ] += self.upper_lower_mask\n",
        "            dots[:, :, nw_w - 1 :: nw_w] += self.left_right_mask\n",
        "\n",
        "        attn = dots.softmax(dim = -1)\n",
        "        out = einsum('b h w i j, b h w j d -> b h w i d', attn, v)\n",
        "        out = rearrange(out, 'b h (nw_h nw_w) (w_h w_w) d -> b (nw_h w_h) (nw_w w_w) (h d)',\n",
        "                        h=h, w_h=self.window_size, w_w=self.window_size, nw_h=nw_h, nw_w=nw_w)\n",
        "        \n",
        "        out = self.to_out(out)\n",
        "\n",
        "        if self.shifted:\n",
        "            out = self.cyclic_back_shift(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "A74wMj5pQFg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SwinBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        heads,\n",
        "        head_dim,\n",
        "        mlp_dim, \n",
        "        shifted,\n",
        "        window_size,\n",
        "        relative_pos_embedding\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.attention_block = Residual(\n",
        "            PreNorm(dim, \n",
        "                WindowAttention(\n",
        "                    dim= dim,\n",
        "                    heads= heads,\n",
        "                    head_dim= head_dim,\n",
        "                    shifted= shifted,\n",
        "                    window_size= window_size,\n",
        "                    relative_pos_embedding= relative_pos_embedding\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "        self.mlp_block = Residual(\n",
        "            PreNorm(dim, FeedForward(dim= dim, hidden_dim= mlp_dim))\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.attention_block(x)\n",
        "        x = self.mlp_block(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "eU2J8gygjZQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchMerging(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downscaling_factor):\n",
        "        super().__init__()\n",
        "        self.downscaling_factor = downscaling_factor\n",
        "        self.patch_merge = nn.Unfold(\n",
        "            kernel_size= downscaling_factor,\n",
        "            stride= downscaling_factor,\n",
        "            padding= 0\n",
        "        )\n",
        "        self.linear = nn.Linear(in_channels * downscaling_factor ** 2, out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        new_h, new_w = h // self.downscaling_factor, w // self.downscaling_factor\n",
        "        x = self.patch_merge(x).view(b, -1, new_h, new_w).permute(0, 2, 3, 1)\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "nVdiOOEYQFkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StageModule(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        hidden_dimension,\n",
        "        layers,\n",
        "        downscaling_factor, \n",
        "        num_heads,\n",
        "        head_dim,\n",
        "        window_size,\n",
        "        relative_pos_embedding\n",
        "    ):\n",
        "        super().__init__()\n",
        "        assert layers % 2 == 0\n",
        "        self.patch_partition = PatchMerging(\n",
        "            in_channels= in_channels,\n",
        "            out_channels= hidden_dimension,\n",
        "            downscaling_factor= downscaling_factor\n",
        "        )\n",
        "        self.layers = nn.ModuleList([])\n",
        "\n",
        "        for _ in range(layers // 2):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                SwinBlock(\n",
        "                    dim= hidden_dimension,\n",
        "                    heads= num_heads,\n",
        "                    head_dim= head_dim,\n",
        "                    mlp_dim= hidden_dimension * 4,\n",
        "                    shifted= False,\n",
        "                    window_size= window_size,\n",
        "                    relative_pos_embedding= relative_pos_embedding\n",
        "                ),\n",
        "                SwinBlock(\n",
        "                    dim= hidden_dimension,\n",
        "                    heads= num_heads,\n",
        "                    head_dim= head_dim,\n",
        "                    mlp_dim= hidden_dimension * 4,\n",
        "                    shifted= True,\n",
        "                    window_size= window_size,\n",
        "                    relative_pos_embedding= relative_pos_embedding\n",
        "                \n",
        "                )\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_partition(x)\n",
        "        for regular_block, shifted_block in self.layers:\n",
        "            x = regular_block(x)\n",
        "            x = shifted_block(x)\n",
        "        \n",
        "\n",
        "        return x.permute(0, 3, 1, 2)"
      ],
      "metadata": {
        "id": "44ouL4WzQFnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SwinTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        hidden_dim,\n",
        "        layers,\n",
        "        heads,\n",
        "        channels= 3,\n",
        "        num_classes= 1000,\n",
        "        head_dim= 32,\n",
        "        window_size= 7,\n",
        "        downscaling_factor= (4, 2, 2, 2),\n",
        "        relative_pos_embedding= True\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.stage1 = StageModule(\n",
        "            in_channels= channels,\n",
        "            hidden_dimension= hidden_dim,\n",
        "            layers= layers[0],\n",
        "            downscaling_factor= downscaling_factor[0],\n",
        "            num_heads= heads[0],\n",
        "            head_dim= head_dim,\n",
        "            window_size= window_size,\n",
        "            relative_pos_embedding= relative_pos_embedding\n",
        "        )\n",
        "\n",
        "        self.stage2 = StageModule(\n",
        "            in_channels= hidden_dim,\n",
        "            hidden_dimension= hidden_dim * 2,\n",
        "            layers= layers[1],\n",
        "            downscaling_factor= downscaling_factor[1],\n",
        "            num_heads= heads[1],\n",
        "            head_dim= head_dim,\n",
        "            window_size= window_size,\n",
        "            relative_pos_embedding= relative_pos_embedding\n",
        "        )\n",
        "\n",
        "        self.stage3 = StageModule(\n",
        "            in_channels= hidden_dim * 2,\n",
        "            hidden_dimension= hidden_dim * 4,\n",
        "            layers= layers[2],\n",
        "            downscaling_factor= downscaling_factor[2],\n",
        "            num_heads= heads[2],\n",
        "            head_dim= head_dim,\n",
        "            window_size= window_size,\n",
        "            relative_pos_embedding= relative_pos_embedding\n",
        "        )\n",
        "\n",
        "        self.stage4 = StageModule(\n",
        "            in_channels= hidden_dim * 4,\n",
        "            hidden_dimension= hidden_dim * 8,\n",
        "            layers= layers[3],\n",
        "            downscaling_factor= downscaling_factor[3],\n",
        "            num_heads= heads[3],\n",
        "            head_dim= head_dim,\n",
        "            window_size= window_size,\n",
        "            relative_pos_embedding= relative_pos_embedding\n",
        "        )\n",
        "\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(hidden_dim * 8),\n",
        "            nn.Linear(hidden_dim * 8, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = self.stage1(img)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.stage4(x)\n",
        "\n",
        "        x = x.mean(dim= [2, 3])\n",
        "        return self.mlp_head(x)"
      ],
      "metadata": {
        "id": "ursPPF7MQFqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = SwinTransformer(\n",
        "    hidden_dim=96,\n",
        "    layers=(2, 2, 6, 2),\n",
        "    heads=(3, 6, 12, 24),\n",
        "    channels=3,\n",
        "    num_classes=3,\n",
        "    head_dim=32,\n",
        "    window_size=7,\n",
        "    downscaling_factor=(4, 2, 2, 2),\n",
        "    relative_pos_embedding=True\n",
        ")\n",
        "dummy_x = torch.randn(1, 3, 224, 224)"
      ],
      "metadata": {
        "id": "KNCSbTEtQFuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = net(dummy_x)  # (1,3)\n",
        "print(net)"
      ],
      "metadata": {
        "id": "a9_MH84x87nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "id": "K4OS5_saAkas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "babf0259-f46b-45ce-be6b-9fea37976875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary"
      ],
      "metadata": {
        "id": "0LBSQeLc-d7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(net, input_size=(32, 3, 224, 224), col_names= [\"input_size\", \"output_size\", \"num_params\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgs90dsVAi3M",
        "outputId": "d022a502-6853-4367-ecf8-287d09de2c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=======================================================================================================================================\n",
              "Layer (type:depth-idx)                                       Input Shape               Output Shape              Param #\n",
              "=======================================================================================================================================\n",
              "SwinTransformer                                              [32, 3, 224, 224]         [32, 3]                   --\n",
              "├─StageModule: 1-1                                           [32, 3, 224, 224]         [32, 96, 56, 56]          --\n",
              "│    └─PatchMerging: 2-1                                     [32, 3, 224, 224]         [32, 56, 56, 96]          --\n",
              "│    │    └─Unfold: 3-1                                      [32, 3, 224, 224]         [32, 48, 3136]            --\n",
              "│    │    └─Linear: 3-2                                      [32, 56, 56, 48]          [32, 56, 56, 96]          4,704\n",
              "│    └─ModuleList: 2-2                                       --                        --                        --\n",
              "│    │    └─ModuleList: 3-3                                  --                        --                        228,244\n",
              "├─StageModule: 1-2                                           [32, 96, 56, 56]          [32, 192, 28, 28]         --\n",
              "│    └─PatchMerging: 2-3                                     [32, 96, 56, 56]          [32, 28, 28, 192]         --\n",
              "│    │    └─Unfold: 3-4                                      [32, 96, 56, 56]          [32, 384, 784]            --\n",
              "│    │    └─Linear: 3-5                                      [32, 28, 28, 384]         [32, 28, 28, 192]         73,920\n",
              "│    └─ModuleList: 2-4                                       --                        --                        --\n",
              "│    │    └─ModuleList: 3-6                                  --                        --                        893,716\n",
              "├─StageModule: 1-3                                           [32, 192, 28, 28]         [32, 384, 14, 14]         --\n",
              "│    └─PatchMerging: 2-5                                     [32, 192, 28, 28]         [32, 14, 14, 384]         --\n",
              "│    │    └─Unfold: 3-7                                      [32, 192, 28, 28]         [32, 768, 196]            --\n",
              "│    │    └─Linear: 3-8                                      [32, 14, 14, 768]         [32, 14, 14, 384]         295,296\n",
              "│    └─ModuleList: 2-6                                       --                        --                        --\n",
              "│    │    └─ModuleList: 3-9                                  --                        --                        3,551,764\n",
              "│    │    └─ModuleList: 3-10                                 --                        --                        3,551,764\n",
              "│    │    └─ModuleList: 3-11                                 --                        --                        3,551,764\n",
              "├─StageModule: 1-4                                           [32, 384, 14, 14]         [32, 768, 7, 7]           --\n",
              "│    └─PatchMerging: 2-7                                     [32, 384, 14, 14]         [32, 7, 7, 768]           --\n",
              "│    │    └─Unfold: 3-12                                     [32, 384, 14, 14]         [32, 1536, 49]            --\n",
              "│    │    └─Linear: 3-13                                     [32, 7, 7, 1536]          [32, 7, 7, 768]           1,180,416\n",
              "│    └─ModuleList: 2-8                                       --                        --                        --\n",
              "│    │    └─ModuleList: 3-14                                 --                        --                        14,176,276\n",
              "├─Sequential: 1-5                                            [32, 768]                 [32, 3]                   --\n",
              "│    └─LayerNorm: 2-9                                        [32, 768]                 [32, 768]                 1,536\n",
              "│    └─Linear: 2-10                                          [32, 768]                 [32, 3]                   2,307\n",
              "=======================================================================================================================================\n",
              "Total params: 27,511,707\n",
              "Trainable params: 27,482,895\n",
              "Non-trainable params: 28,812\n",
              "Total mult-adds (M): 879.39\n",
              "=======================================================================================================================================\n",
              "Input size (MB): 19.27\n",
              "Forward/backward pass size (MB): 4171.63\n",
              "Params size (MB): 109.92\n",
              "Estimated Total Size (MB): 4300.82\n",
              "======================================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.module import _addindent\n",
        "import torch\n",
        "import numpy as np\n",
        "def torch_summarize(model, show_weights=True, show_parameters=True):\n",
        "    \"\"\"Summarizes torch model by showing trainable parameters and weights.\"\"\"\n",
        "    tmpstr = model.__class__.__name__ + ' (\\n'\n",
        "    for key, module in model._modules.items():\n",
        "        # if it contains layers let call it recursively to get params and weights\n",
        "        if type(module) in [\n",
        "            torch.nn.modules.container.Container,\n",
        "            torch.nn.modules.container.Sequential\n",
        "        ]:\n",
        "            modstr = torch_summarize(module)\n",
        "        else:\n",
        "            modstr = module.__repr__()\n",
        "        modstr = _addindent(modstr, 2)\n",
        "\n",
        "        params = sum([np.prod(p.size()) for p in module.parameters()])\n",
        "        weights = tuple([tuple(p.size()) for p in module.parameters()])\n",
        "\n",
        "        tmpstr += '  (' + key + '): ' + modstr \n",
        "        if show_weights:\n",
        "            tmpstr += ', weights={}'.format(weights)\n",
        "        if show_parameters:\n",
        "            tmpstr +=  ', parameters={}'.format(params)\n",
        "        tmpstr += '\\n'   \n",
        "\n",
        "    tmpstr = tmpstr + ')'\n",
        "    return tmpstr"
      ],
      "metadata": {
        "id": "T2AgOBYeAzKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch_summarize(net))"
      ],
      "metadata": {
        "id": "nt8IIZeyEmBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_output_shape(model, image_dim):\n",
        "    return model(torch.rand(*(image_dim))).data.shape"
      ],
      "metadata": {
        "id": "Co7agVTzEp9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_output_shape(net, (32, 3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6CQ4RZYFKU8",
        "outputId": "0bd6bf95-810e-4bf1-8a42-3a3383c9dabb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2kR7cDO6ExSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VfYXQm0HExP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StageModule(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dimension, layers, downscaling_factor, num_heads, head_dim, window_size,\n",
        "                 relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        assert layers % 2 == 0, 'Stage layers need to be divisible by 2 for regular and shifted block.'\n",
        "\n",
        "        self.patch_partition = PatchMerging(in_channels=in_channels, out_channels=hidden_dimension,\n",
        "                                            downscaling_factor=downscaling_factor)\n",
        "\n",
        "        self.layers = nn.ModuleList([])\n",
        "        for _ in range(layers // 2):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                SwinBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
        "                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
        "                SwinBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
        "                          shifted=True, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_partition(x)\n",
        "        for regular_block, shifted_block in self.layers:\n",
        "            x = regular_block(x)\n",
        "            x = shifted_block(x)\n",
        "        return x.permute(0, 3, 1, 2)"
      ],
      "metadata": {
        "id": "tcTGai9OExNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stageM = StageModule(\n",
        "    in_channels, \n",
        "    hidden_dimension, \n",
        "    layers, \n",
        "    downscaling_factor, \n",
        "    num_heads, \n",
        "    head_dim, \n",
        "    window_size,\n",
        "    relative_pos_embedding\n",
        ")"
      ],
      "metadata": {
        "id": "c5lfUjm7Ex6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vi68k6pEGPaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchMerging(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downscaling_factor):\n",
        "        super().__init__()\n",
        "        self.downscaling_factor = downscaling_factor\n",
        "        self.patch_merge = nn.Unfold(\n",
        "            kernel_size= downscaling_factor,\n",
        "            stride= downscaling_factor,\n",
        "            padding= 0\n",
        "        )\n",
        "        self.linear = nn.Linear(in_channels * downscaling_factor ** 2, out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        new_h, new_w = h // self.downscaling_factor, w // self.downscaling_factor\n",
        "        x = self.patch_merge(x).view(b, -1, new_h, new_w).permute(0, 2, 3, 1)\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "0jFXiqcAGPUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = PatchMerging(in_channels=3, out_channels=32,\n",
        "                  downscaling_factor=4)"
      ],
      "metadata": {
        "id": "yeu4SPMyGRKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(net, input_size=(32, 3, 224, 224), col_names= [\"input_size\", \"output_size\", \"num_params\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YAqNlgRGZhY",
        "outputId": "2cc3f840-6a5d-40c1-e5d5-af024845e0ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===================================================================================================================\n",
              "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
              "===================================================================================================================\n",
              "PatchMerging                             [32, 3, 224, 224]         [32, 56, 56, 32]          --\n",
              "├─Unfold: 1-1                            [32, 3, 224, 224]         [32, 48, 3136]            --\n",
              "├─Linear: 1-2                            [32, 56, 56, 48]          [32, 56, 56, 32]          1,568\n",
              "===================================================================================================================\n",
              "Total params: 1,568\n",
              "Trainable params: 1,568\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 0.05\n",
              "===================================================================================================================\n",
              "Input size (MB): 19.27\n",
              "Forward/backward pass size (MB): 25.69\n",
              "Params size (MB): 0.01\n",
              "Estimated Total Size (MB): 44.96\n",
              "==================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zdD4CfjtNkmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GTN"
      ],
      "metadata": {
        "id": "1Rj-ZtpDFazc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kh2PKUHgFc1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Anomaly Transformer**"
      ],
      "metadata": {
        "id": "KEP2W8PUQ2Vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math, os, pickle, collections, argparse, time\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.backends import cudnn"
      ],
      "metadata": {
        "id": "IFdpm22iQ7DK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Anomaly Attention"
      ],
      "metadata": {
        "id": "loFw1M9sYKOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TriangularCausalMask():\n",
        "    def __init__(self, B, L, device= 'cpu'):\n",
        "        mask_shape = [B, 1, L, L]\n",
        "        with torch.no_grad():\n",
        "            self._mask = torch.triu(\n",
        "                torch.ones(\n",
        "                    mask_shape, dtype= torch.bool\n",
        "                ), diagonal= 1\n",
        "            ).to(device)\n",
        "        \n",
        "    @property\n",
        "    def mask(self):\n",
        "        return self.mask\n",
        "\n",
        "\n",
        "class AnomalyAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        win_size, \n",
        "        mask_flag= True,\n",
        "        scale= None,\n",
        "        attention_dropout= 0.0,\n",
        "        output_attention= False\n",
        "    ):\n",
        "        super(AnomalyAttention, self).__init__()\n",
        "        self.scale = scale\n",
        "        self.mask_flag = mask_flag\n",
        "        self.output_attention = output_attention\n",
        "        self.dropout = nn.Dropout(attention_dropout)\n",
        "        window_size = win_size\n",
        "        self.distances = torch.zeros((window_size, window_size)).cuda()\n",
        "        for i in range(window_size):\n",
        "            for j in range(window_size):\n",
        "                self.distances[i][j] = abs(i - j)\n",
        "        \n",
        "    def forward(\n",
        "        self,\n",
        "        queries,\n",
        "        keys,\n",
        "        values, \n",
        "        sigma,\n",
        "        attn_mask\n",
        "    ): \n",
        "        B, L, H, E = queries.shape    ## Batch_size, \n",
        "        _, S, _, D = values.shape  ## Isn't both the queries and values same shape??\n",
        "        scale = self.scale or 1. / math.sqrt(E)\n",
        "\n",
        "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n",
        "        if self.mask_flag:\n",
        "            if attn_mask is None:\n",
        "                attn_mask = TriangularCausalMask(B, L, device= queries.device)\n",
        "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
        "        attn = scale * scores\n",
        "\n",
        "        sigma = sigma.transpose(1, 2) # B L H ->  B H L\n",
        "        window_size = attn.shape[-1]\n",
        "        sigma = torch.sigmoid(sigma * 5) + 1e-5\n",
        "        sigma = torch.pow(3, sigma) - 1\n",
        "        sigma = sigma.unsqueeze(-1).repeat(1, 1, 1, window_size)\n",
        "        prior = self.distances.unsqueeze(0).unsqueeze(0).repeat(\n",
        "                    sigma.shape[0], sigma.shape[1], 1, 1\n",
        "                ).cuda()\n",
        "        prior = 1.0 / (math.sqrt(2 * math.pi) * sigma) * torch.exp(-prior ** 2 / (2 * sigma ** 2))\n",
        "\n",
        "        series = self.dropout(torch.softmax(attn, dim= 1))\n",
        "        V = torch.einsum(\"bhls,bshd->blhd\", series, values)\n",
        "        if self.output_attention:\n",
        "            return (V.contiguous(), series, prior, sigma)\n",
        "        else:\n",
        "            return (V.contiguous(), None)\n"
      ],
      "metadata": {
        "id": "M6w6pRvzRQ7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionLayer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attention,\n",
        "        d_model,\n",
        "        n_heads,\n",
        "        d_keys= None,\n",
        "        d_values= None\n",
        "    ):\n",
        "        super(AttentionLayer, self).__init__()\n",
        "        d_keys = d_keys or (d_model // n_heads)\n",
        "        d_values = d_values or (d_model // n_heads)\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "        self.inner_attention = attention\n",
        "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
        "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
        "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
        "        self.sigma_projection = nn.Linear(d_model, n_heads)\n",
        "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        queries,\n",
        "        keys,\n",
        "        values, \n",
        "        attn_mask\n",
        "    ):\n",
        "        B, L, _ = queries.shape\n",
        "        _, S, _ = keys.shape\n",
        "        H = self.n_heads\n",
        "        x = queries\n",
        "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
        "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
        "        values = self.value_projection(values).view(B, S, H, -1)\n",
        "        sigma = self.sigma_projection(x).view(B, L, H)\n",
        "\n",
        "        out, series, prior, sigma = self.inner_attention(\n",
        "            queries,\n",
        "            keys,\n",
        "            values, \n",
        "            sigma,\n",
        "            attn_mask\n",
        "        )\n",
        "        out = out.view(B, L, -1)\n",
        "        return self.out_projection(out), series, prior, sigma"
      ],
      "metadata": {
        "id": "MKvOhFv0WAlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attention,\n",
        "        d_model,\n",
        "        d_ff= None,\n",
        "        dropout= 0.1,\n",
        "        activation= 'relu'\n",
        "    ):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        d_ff = d_ff or d_model * 4\n",
        "        self.attention = attention\n",
        "        self.conv1 = nn.Conv1d(in_channels= d_model, out_channels= d_ff, kernel_size= 1)\n",
        "        self.conv2 = nn.Conv1d(in_channels= d_ff, out_channels= d_model, kernel_size= 1)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.activation = F.relu if activation == 'relu' else F.gelu\n",
        "\n",
        "    def forward(\n",
        "        self, \n",
        "        x,\n",
        "        attn_mask= None\n",
        "    ):  \n",
        "        new_x, attn, mask, sigma = self.attention(\n",
        "            x, x, x, attn_mask= attn_mask\n",
        "        )\n",
        "        x = x + self.dropout(new_x)\n",
        "        y = x = self.norm1(x)\n",
        "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
        "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
        "        return self.norm2(x + y), attn, mask, sigma\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_layers,\n",
        "        norm_layer= None\n",
        "    ):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.attn_layers = nn.ModuleList(attn_layers)\n",
        "        self.norm = norm_layer\n",
        "\n",
        "    def forward(\n",
        "        self, \n",
        "        x, \n",
        "        attn_mask= None\n",
        "    ):\n",
        "        series_list = []\n",
        "        prior_list = []\n",
        "        sigma_list = []\n",
        "\n",
        "        for attn_layer in self.attn_layers:\n",
        "            x, series, prior, sigma = attn_layer(x, attn_mask= attn_mask)\n",
        "            series_list.append(series)\n",
        "            prior_list.append(prior)\n",
        "            sigma_list.append(sigma)\n",
        "\n",
        "\n",
        "        if self.norm is not None:\n",
        "            x = self.norm(x)\n",
        "        \n",
        "        return x, series_list, prior_list, sigma_list\n",
        "\n",
        "class AnomalyTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self, \n",
        "        win_size,\n",
        "        enc_in,\n",
        "        c_out,\n",
        "        d_model= 512,\n",
        "        n_heads= 8,\n",
        "        e_layers= 3,\n",
        "        d_ff = 512,\n",
        "        dropout= 0.0,\n",
        "        activation= 'gelu',\n",
        "        output_attention= True\n",
        "    ):\n",
        "        super(AnomalyTransformer, self).__init__()\n",
        "        self.output_attention = output_attention\n",
        "\n",
        "        self.embedding= DataEmbedding(enc_in, d_model, dropout)\n",
        "        self.encoder = Encoder(\n",
        "            [\n",
        "                EncoderLayer(\n",
        "                    AttentionLayer(\n",
        "                        AnomalyAttention(\n",
        "                            win_size= win_size, \n",
        "                            mask_flag= False,\n",
        "                            scale= None,\n",
        "                            attention_dropout= dropout,\n",
        "                            output_attention= output_attention\n",
        "                        ), \n",
        "                        d_model= d_model,\n",
        "                        n_heads= n_heads,\n",
        "                    ),\n",
        "                    d_model= d_model,\n",
        "                    d_ff= d_ff,\n",
        "                    dropout= dropout,\n",
        "                    activation= activation\n",
        "                ) for l in range(e_layers)\n",
        "            ],\n",
        "            norm_layer= torch.nn.LayerNorm(d_model)\n",
        "        )\n",
        "\n",
        "        self.projection = nn.Linear(d_model, c_out, bias= True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc_out = self.embedding(x)\n",
        "        enc_out, series, prior, sigmas = self.encoder(enc_out)\n",
        "        enc_out = self.projection(enc_out)\n",
        "\n",
        "        if self.output_attention:\n",
        "            return enc_out, series, prior, sigmas\n",
        "        else:\n",
        "            return enc_out"
      ],
      "metadata": {
        "id": "dodfKCP4WAiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding"
      ],
      "metadata": {
        "id": "lH07jyCBYSHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        d_model,\n",
        "        max_len= 5000\n",
        "    ):\n",
        "        super(PositionalEmbedding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model).float()\n",
        "        pe.require_grad = False\n",
        "\n",
        "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
        "        div_term = (torch.arange(\n",
        "            0, d_model, 2\n",
        "        ).float() * -(math.log(10000.0) / d_model)).exp()\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pe[:, :x.size(1)]"
      ],
      "metadata": {
        "id": "vd7DlHJgWAf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        c_in,\n",
        "        d_model\n",
        "    ):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
        "        self.tokenConv = nn.Conv1d(\n",
        "            in_channels= c_in,\n",
        "            out_channels= d_model,\n",
        "            kernel_size= 3,\n",
        "            padding= padding,\n",
        "            padding_mode= 'circular',\n",
        "            bias= False\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d):\n",
        "                nn.init.kaiming_normal_(\n",
        "                    m.weight,\n",
        "                    mode= 'fan_in',\n",
        "                    nonlinearity= 'leaky_relu'\n",
        "                )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "OyAGm9_gWAdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataEmbedding(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        c_in,\n",
        "        d_model,\n",
        "        dropout= 0.0\n",
        "    ):\n",
        "        super(DataEmbedding, self).__init__()\n",
        "\n",
        "        self.value_embedding = TokenEmbedding(\n",
        "            c_in= c_in,\n",
        "            d_model= d_model\n",
        "        )\n",
        "        self.position_embedding = PositionalEmbedding(\n",
        "            d_model= d_model\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.value_embedding(x) + self.position_embedding(x)\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "5AtqhtgGWAaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loader"
      ],
      "metadata": {
        "id": "FAa_lDeKYf6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PSMSegLoader(object):\n",
        "    def __init__(\n",
        "        self,\n",
        "        data_path,\n",
        "        win_size,\n",
        "        step,\n",
        "        mode= 'train'\n",
        "    ):\n",
        "        self.mode = mode\n",
        "        self.step = step\n",
        "        self.win_size = win_size\n",
        "        self.scaler = StandardScaler()\n",
        "        \n",
        "        data = pd.read_csv(os.path.join(data_path, 'train.csv'))\n",
        "        data = data.values[:, 1 : ]\n",
        "        data = np.nan_to_num(data)\n",
        "        self.scaler.fit(data)\n",
        "        data = self.scaler.transform(data)\n",
        "        \n",
        "        test_data = pd.read_csv(os.path.join(data_path, 'test.csv'))\n",
        "        test_data = test_data.values[:, 1 : ]\n",
        "        test_data = np.nan_to_num(test_data)\n",
        "        self.test = self.scaler.transform(test_data)\n",
        "        self.train = data\n",
        "        self.val = self.test\n",
        "\n",
        "        test_labels = pd.read_csv(os.path.join(data_path, 'test_label.csv'))\n",
        "        self.test_labels = test_labels.values[: , 1 : ]\n",
        "\n",
        "        print(\"test: \", self.test.shape)\n",
        "        print(\"train: \", self.train.shape)\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.mode == 'train':\n",
        "            return (self.train.shape[0] - self.win_size) // self.step + 1\n",
        "        elif self.mode == 'val':\n",
        "            return (self.val.shape[0] - self.win_size) // self.step + 1\n",
        "        elif self.mode == 'test':\n",
        "            return (self.test.shape[0] - self.win_size) // self.step + 1\n",
        "        else:\n",
        "            return (self.test.shape[0] - self.win_size) // self.win_size + 1\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        index = index * self.step\n",
        "        if self.mode == 'train':\n",
        "            return np.float32(self.train[index : index + self.win_size]), \\\n",
        "                  np.float32(self.test_labels[0: self.win_size])\n",
        "        elif self.mode == 'val':\n",
        "            return np.float32(self.val[index : index + self.win_size]), \\\n",
        "                  np.float32(self.test_labels[0 : self.win_size])\n",
        "        elif (self.mode == 'test'):\n",
        "            return np.float32(self.test[index : index + self.win_size]), \\\n",
        "                np.float32(self.test_labels[index : index + self.win_size])\n",
        "        else:\n",
        "            return np.float32(self.test[\n",
        "                      index // self.step * self.win_size : \\\n",
        "                      index // self.step * self.win_size + self.win_size\n",
        "                  ]), \\\n",
        "                  np.float32(self.test_labels[\n",
        "                      index // self.step * self.win_size : \\\n",
        "                      index // self.step * self.win_size + self.win_size\n",
        "                  ])"
      ],
      "metadata": {
        "id": "638umRfRWAXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilities"
      ],
      "metadata": {
        "id": "1f0MrgA_ZVv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_kl_loss(p, q):\n",
        "    res = p * (torch.log(p + 0.0001) - torch.log(q + 0.0001))\n",
        "    return torch.mean(torch.sum(res, dim=-1), dim=1)\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, lr_):\n",
        "    lr_adjust = {epoch: lr_ * (0.5 ** ((epoch - 1) // 1))}\n",
        "    if epoch in lr_adjust.keys():\n",
        "        lr = lr_adjust[epoch]\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "        print('Updating learning rate to {}'.format(lr))\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, verbose=False, dataset_name='', delta=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.best_score2 = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.val_loss2_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.dataset = dataset_name\n",
        "\n",
        "    def __call__(self, val_loss, val_loss2, model, path):\n",
        "        score = -val_loss\n",
        "        score2 = -val_loss2\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.best_score2 = score2\n",
        "            self.save_checkpoint(val_loss, val_loss2, model, path)\n",
        "        elif score < self.best_score + self.delta or score2 < self.best_score2 + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.best_score2 = score2\n",
        "            self.save_checkpoint(val_loss, val_loss2, model, path)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, val_loss2, model, path):\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), os.path.join(path, str(self.dataset) + '_checkpoint.pth'))\n",
        "        self.val_loss_min = val_loss\n",
        "        self.val_loss2_min = val_loss2\n",
        "\n",
        "\n",
        "class Solver(object):\n",
        "    DEFAULTS = {}\n",
        "\n",
        "    def __init__(self, config):\n",
        "\n",
        "        self.__dict__.update(Solver.DEFAULTS, **config)\n",
        "\n",
        "        self.train_loader = get_loader_segment(self.data_path, batch_size=self.batch_size, win_size=self.win_size,\n",
        "                                               mode='train',\n",
        "                                               dataset=self.dataset)\n",
        "        self.vali_loader = get_loader_segment(self.data_path, batch_size=self.batch_size, win_size=self.win_size,\n",
        "                                              mode='val',\n",
        "                                              dataset=self.dataset)\n",
        "        self.test_loader = get_loader_segment(self.data_path, batch_size=self.batch_size, win_size=self.win_size,\n",
        "                                              mode='test',\n",
        "                                              dataset=self.dataset)\n",
        "        self.thre_loader = get_loader_segment(self.data_path, batch_size=self.batch_size, win_size=self.win_size,\n",
        "                                              mode='thre',\n",
        "                                              dataset=self.dataset)\n",
        "\n",
        "        self.build_model()\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "    def build_model(self):\n",
        "        self.model = AnomalyTransformer(win_size=self.win_size, enc_in=self.input_c, c_out=self.output_c, e_layers=3)\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            self.model.cuda()\n",
        "\n",
        "    def vali(self, vali_loader):\n",
        "        self.model.eval()\n",
        "\n",
        "        loss_1 = []\n",
        "        loss_2 = []\n",
        "        for i, (input_data, _) in enumerate(vali_loader):\n",
        "            input = input_data.float().to(self.device)\n",
        "            output, series, prior, _ = self.model(input)\n",
        "            series_loss = 0.0\n",
        "            prior_loss = 0.0\n",
        "            for u in range(len(prior)):\n",
        "                series_loss += (torch.mean(my_kl_loss(series[u], (\n",
        "                        prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,\n",
        "                                                                                               self.win_size)).detach())) + torch.mean(\n",
        "                    my_kl_loss(\n",
        "                        (prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,\n",
        "                                                                                                self.win_size)).detach(),\n",
        "                        series[u])))\n",
        "                prior_loss += (torch.mean(\n",
        "                    my_kl_loss((prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,\n",
        "                                                                                                       self.win_size)),\n",
        "                               series[u].detach())) + torch.mean(\n",
        "                    my_kl_loss(series[u].detach(),\n",
        "                               (prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,\n",
        "                                                                                                       self.win_size)))))\n",
        "            series_loss = series_loss / len(prior)\n",
        "            prior_loss = prior_loss / len(prior)\n",
        "\n",
        "            rec_loss = self.criterion(output, input)\n",
        "            loss_1.append((rec_loss - self.k * series_loss).item())\n",
        "            loss_2.append((rec_loss + self.k * prior_loss).item())\n",
        "\n",
        "        return np.average(loss_1), np.average(loss_2)\n",
        "\n",
        "    def train(self):\n",
        "\n",
        "        print(\"======================TRAIN MODE======================\")\n",
        "\n",
        "        time_now = time.time()\n",
        "        path = self.model_save_path\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "        early_stopping = EarlyStopping(patience=3, verbose=True, dataset_name=self.dataset)\n",
        "        train_steps = len(self.train_loader)\n",
        "\n",
        "        for epoch in range(self.num_epochs):\n",
        "            iter_count = 0\n",
        "            loss1_list = []\n",
        "\n",
        "            epoch_time = time.time()\n",
        "            self.model.train()\n",
        "            for i, (input_data, labels) in enumerate(self.train_loader):\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                iter_count += 1\n",
        "                input = input_data.float().to(self.device)\n",
        "\n",
        "                output, series, prior, _ = self.model(input)\n",
        "\n",
        "                # calculate Association discrepancy\n",
        "                series_loss = 0.0\n",
        "                prior_loss = 0.0\n",
        "                for u in range(len(prior)):\n",
        "                    series_loss += (torch.mean(my_kl_loss(series[u], (\n",
        "                            prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,\n",
        "                                                                                                   self.win_size)).detach())) + torch.mean(\n",
        "                        my_kl_loss((prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,\n",
        "                                                                                                           self.win_size)).detach(),\n",
        "                                   series[u])))\n",
        "                    prior_loss += (torch.mean(my_kl_loss(\n",
        "                        (prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,\n",
        "                                                                                                self.win_size)),\n",
        "                        series[u].detach())) + torch.mean(\n",
        "                        my_kl_loss(series[u].detach(), (\n",
        "                                prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,\n",
        "                                                                                                       self.win_size)))))\n",
        "                series_loss = series_loss / len(prior)\n",
        "                prior_loss = prior_loss / len(prior)\n",
        "\n",
        "                rec_loss = self.criterion(output, input)\n",
        "\n",
        "                loss1_list.append((rec_loss - self.k * series_loss).item())\n",
        "                loss1 = rec_loss - self.k * series_loss\n",
        "                loss2 = rec_loss + self.k * prior_loss\n",
        "\n",
        "                if (i + 1) % 100 == 0:\n",
        "                    speed = (time.time() - time_now) / iter_count\n",
        "                    left_time = speed * ((self.num_epochs - epoch) * train_steps - i)\n",
        "                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
        "                    iter_count = 0\n",
        "                    time_now = time.time()\n",
        "\n",
        "                # Minimax strategy\n",
        "                loss1.backward(retain_graph=True)\n",
        "                loss2.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "            print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
        "            train_loss = np.average(loss1_list)\n",
        "\n",
        "            vali_loss1, vali_loss2 = self.vali(self.test_loader)\n",
        "\n",
        "            print(\n",
        "                \"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} \".format(\n",
        "                    epoch + 1, train_steps, train_loss, vali_loss1))\n",
        "            early_stopping(vali_loss1, vali_loss2, self.model, path)\n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "            adjust_learning_rate(self.optimizer, epoch + 1, self.lr)\n",
        "\n",
        "    def test(self):\n",
        "        self.model.load_state_dict(\n",
        "            torch.load(\n",
        "                os.path.join(str(self.model_save_path), str(self.dataset) + '_checkpoint.pth')))\n",
        "        self.model.eval()\n",
        "        temperature = 50\n",
        "\n",
        "        print(\"======================TEST MODE======================\")\n",
        "\n",
        "        criterion = nn.MSELoss(reduce=False)\n",
        "\n",
        "        # (1) stastic on the train set\n",
        "        attens_energy = []\n",
        "        for i, (input_data, labels) in enumerate(self.train_loader):\n",
        "            input = input_data.float().to(self.device)\n",
        "            output, series, prior, _ = self.model(input)\n",
        "            loss = torch.mean(criterion(input, output), dim=-1)\n",
        "            series_loss = 0.0\n",
        "            prior_loss = 0.0\n",
        "            for u in range(len(prior)):\n",
        "                if u == 0:\n",
        "                    series_loss = my_kl_loss(series[u], (\n",
        "                            prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,\n",
        "                                                                                                   self.win_size)).detach()) * temperature\n",
        "                    prior_loss = my_kl_loss(\n",
        "                        (prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,\n",
        "                                                                                                self.win_size)),\n",
        "                        series[u].detach()) * temperature\n",
        "                else:\n",
        "                    series_loss += my_kl_loss(series[u], (\n",
        "                            prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,\n",
        "                                                                                                   self.win_size)).detach()) * temperature\n",
        "                    prior_loss += my_kl_loss(\n",
        "                        (prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,\n",
        "                                                                                                self.win_size)),\n",
        "                        series[u].detach()) * temperature\n",
        "\n",
        "            metric = torch.softmax((-series_loss - prior_loss), dim=-1)\n",
        "            cri = metric * loss\n",
        "            cri = cri.detach().cpu().numpy()\n",
        "            attens_energy.append(cri)\n",
        "\n",
        "        attens_energy = np.concatenate(attens_energy, axis=0).reshape(-1)\n",
        "        train_energy = np.array(attens_energy)\n",
        "\n",
        "        # (2) find the threshold\n",
        "        attens_energy = []\n",
        "        for i, (input_data, labels) in enumerate(self.thre_loader):\n",
        "            input = input_data.float().to(self.device)\n",
        "            output, series, prior, _ = self.model(input)\n",
        "\n",
        "            loss = torch.mean(criterion(input, output), dim=-1)\n",
        "\n",
        "            series_loss = 0.0\n",
        "            prior_loss = 0.0\n",
        "            for u in range(len(prior)):\n",
        "                if u == 0:\n",
        "                    series_loss = my_kl_loss(series[u], (\n",
        "                            prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,\n",
        "                                                                                                   self.win_size)).detach()) * temperature\n",
        "                    prior_loss = my_kl_loss(\n",
        "                        (prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,\n",
        "                                                                                                self.win_size)),\n",
        "                        series[u].detach()) * temperature\n",
        "                else:\n",
        "                    series_loss += my_kl_loss(series[u], (\n",
        "                            prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,\n",
        "                                                                                                   self.win_size)).detach()) * temperature\n",
        "                    prior_loss += my_kl_loss(\n",
        "                        (prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,\n",
        "                                                                                                self.win_size)),\n",
        "                        series[u].detach()) * temperature\n",
        "            # Metric\n",
        "            metric = torch.softmax((-series_loss - prior_loss), dim=-1)\n",
        "            cri = metric * loss\n",
        "            cri = cri.detach().cpu().numpy()\n",
        "            attens_energy.append(cri)\n",
        "\n",
        "        attens_energy = np.concatenate(attens_energy, axis=0).reshape(-1)\n",
        "        test_energy = np.array(attens_energy)\n",
        "        combined_energy = np.concatenate([train_energy, test_energy], axis=0)\n",
        "        thresh = np.percentile(combined_energy, 100 - self.anormly_ratio)\n",
        "        print(\"Threshold :\", thresh)\n",
        "\n",
        "        # (3) evaluation on the test set\n",
        "        test_labels = []\n",
        "        attens_energy = []\n",
        "        for i, (input_data, labels) in enumerate(self.thre_loader):\n",
        "            input = input_data.float().to(self.device)\n",
        "            output, series, prior, _ = self.model(input)\n",
        "\n",
        "            loss = torch.mean(criterion(input, output), dim=-1)\n",
        "\n",
        "            series_loss = 0.0\n",
        "            prior_loss = 0.0\n",
        "            for u in range(len(prior)):\n",
        "                if u == 0:\n",
        "                    series_loss = my_kl_loss(series[u], (\n",
        "                            prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,\n",
        "                                                                                                   self.win_size)).detach()) * temperature\n",
        "                    prior_loss = my_kl_loss(\n",
        "                        (prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,\n",
        "                                                                                                self.win_size)),\n",
        "                        series[u].detach()) * temperature\n",
        "                else:\n",
        "                    series_loss += my_kl_loss(series[u], (\n",
        "                            prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,\n",
        "                                                                                                   self.win_size)).detach()) * temperature\n",
        "                    prior_loss += my_kl_loss(\n",
        "                        (prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,\n",
        "                                                                                                self.win_size)),\n",
        "                        series[u].detach()) * temperature\n",
        "            metric = torch.softmax((-series_loss - prior_loss), dim=-1)\n",
        "\n",
        "            cri = metric * loss\n",
        "            cri = cri.detach().cpu().numpy()\n",
        "            attens_energy.append(cri)\n",
        "            test_labels.append(labels)\n",
        "\n",
        "        attens_energy = np.concatenate(attens_energy, axis=0).reshape(-1)\n",
        "        test_labels = np.concatenate(test_labels, axis=0).reshape(-1)\n",
        "        test_energy = np.array(attens_energy)\n",
        "        test_labels = np.array(test_labels)\n",
        "\n",
        "        pred = (test_energy > thresh).astype(int)\n",
        "\n",
        "        gt = test_labels.astype(int)\n",
        "\n",
        "        print(\"pred:   \", pred.shape)\n",
        "        print(\"gt:     \", gt.shape)\n",
        "\n",
        "        # detection adjustment\n",
        "        anomaly_state = False\n",
        "        for i in range(len(gt)):\n",
        "            if gt[i] == 1 and pred[i] == 1 and not anomaly_state:\n",
        "                anomaly_state = True\n",
        "                for j in range(i, 0, -1):\n",
        "                    if gt[j] == 0:\n",
        "                        break\n",
        "                    else:\n",
        "                        if pred[j] == 0:\n",
        "                            pred[j] = 1\n",
        "                for j in range(i, len(gt)):\n",
        "                    if gt[j] == 0:\n",
        "                        break\n",
        "                    else:\n",
        "                        if pred[j] == 0:\n",
        "                            pred[j] = 1\n",
        "            elif gt[i] == 0:\n",
        "                anomaly_state = False\n",
        "            if anomaly_state:\n",
        "                pred[i] = 1\n",
        "\n",
        "        pred = np.array(pred)\n",
        "        gt = np.array(gt)\n",
        "        print(\"pred: \", pred.shape)\n",
        "        print(\"gt:   \", gt.shape)\n",
        "\n",
        "        from sklearn.metrics import precision_recall_fscore_support\n",
        "        from sklearn.metrics import accuracy_score\n",
        "        accuracy = accuracy_score(gt, pred)\n",
        "        precision, recall, f_score, support = precision_recall_fscore_support(gt, pred,\n",
        "                                                                              average='binary')\n",
        "        print(\n",
        "            \"Accuracy : {:0.4f}, Precision : {:0.4f}, Recall : {:0.4f}, F-score : {:0.4f} \".format(\n",
        "                accuracy, precision,\n",
        "                recall, f_score))\n",
        "\n",
        "        return accuracy, precision, recall, f_score"
      ],
      "metadata": {
        "id": "jyeQZll5WAVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loader_segment(data_path, batch_size, win_size=100, step=100, mode='train', dataset='KDD'):\n",
        "    if (dataset == 'SMD'):\n",
        "        dataset = SMDSegLoader(data_path, win_size, step, mode)\n",
        "    elif (dataset == 'MSL'):\n",
        "        dataset = MSLSegLoader(data_path, win_size, 1, mode)\n",
        "    elif (dataset == 'SMAP'):\n",
        "        dataset = SMAPSegLoader(data_path, win_size, 1, mode)\n",
        "    elif (dataset == 'PSM'):\n",
        "        dataset = PSMSegLoader(data_path, win_size, 1, mode)\n",
        "\n",
        "    shuffle = False\n",
        "    if mode == 'train':\n",
        "        shuffle = True\n",
        "\n",
        "    data_loader = DataLoader(dataset=dataset,\n",
        "                             batch_size=batch_size,\n",
        "                             shuffle=shuffle,\n",
        "                             num_workers=0)\n",
        "    return data_loader"
      ],
      "metadata": {
        "id": "QQjqI-6fWAPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main"
      ],
      "metadata": {
        "id": "tLNI9ct6Zy4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def str2bool(v):\n",
        "    return v.lower() in ('true')\n",
        "\n",
        "\n",
        "def main(config):\n",
        "    cudnn.benchmark = True\n",
        "    if (not os.path.exists(config.model_save_path)):\n",
        "        os.mkdir(config.model_save_path)\n",
        "    solver = Solver(vars(config))\n",
        "\n",
        "    if config.mode == 'train':\n",
        "        solver.train()\n",
        "    elif config.mode == 'test':\n",
        "        solver.test()\n",
        "\n",
        "    return solver\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    parser.add_argument('--lr', type=float, default=1e-4)\n",
        "    parser.add_argument('--num_epochs', type=int, default=10)\n",
        "    parser.add_argument('--k', type=int, default=3)\n",
        "    parser.add_argument('--win_size', type=int, default=100)\n",
        "    parser.add_argument('--input_c', type=int, default=25)\n",
        "    parser.add_argument('--output_c', type=int, default=25)\n",
        "    parser.add_argument('--batch_size', type=int, default=1024)\n",
        "    parser.add_argument('--pretrained_model', type=str, default=None)\n",
        "    parser.add_argument('--dataset', type=str, default='PSM')\n",
        "    parser.add_argument('--mode', type=str, default='train', choices=['train', 'test'])\n",
        "    parser.add_argument('--data_path', type=str, default='/content/')\n",
        "    parser.add_argument('--model_save_path', type=str, default='checkpoints')\n",
        "    parser.add_argument('--anormly_ratio', type=float, default=4.00)\n",
        "\n",
        "    config, unknown = parser.parse_known_args()\n",
        "\n",
        "    args = vars(config)\n",
        "    print('------------ Options -------------')\n",
        "    for k, v in sorted(args.items()):\n",
        "        print('%s: %s' % (str(k), str(v)))\n",
        "    print('-------------- End ----------------')\n",
        "    main(config)"
      ],
      "metadata": {
        "id": "9Xmm-mWhWANA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        },
        "outputId": "39cf62d3-2ce8-481b-d523-bb0770078f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------ Options -------------\n",
            "anormly_ratio: 4.0\n",
            "batch_size: 1024\n",
            "data_path: /content/\n",
            "dataset: PSM\n",
            "input_c: 25\n",
            "k: 3\n",
            "lr: 0.0001\n",
            "mode: train\n",
            "model_save_path: checkpoints\n",
            "num_epochs: 10\n",
            "output_c: 25\n",
            "pretrained_model: None\n",
            "win_size: 100\n",
            "-------------- End ----------------\n",
            "test:  (87841, 25)\n",
            "train:  (132481, 25)\n",
            "test:  (87841, 25)\n",
            "train:  (132481, 25)\n",
            "test:  (87841, 25)\n",
            "train:  (132481, 25)\n",
            "test:  (87841, 25)\n",
            "train:  (132481, 25)\n",
            "======================TRAIN MODE======================\n",
            "\tspeed: 0.6193s/iter; left time: 743.7951s\n",
            "Epoch: 1 cost time: 79.06656241416931\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-efb0069802db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-------------- End ----------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-efb0069802db>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-f85d196c61ac>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss1_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mvali_loss1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvali_loss2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvali\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             print(\n",
            "\u001b[0;32m<ipython-input-11-f85d196c61ac>\u001b[0m in \u001b[0;36mvali\u001b[0;34m(self, vali_loader)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvali_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0mseries_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mprior_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-be499835c34b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0menc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigmas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0menc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-be499835c34b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mattn_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mseries_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mprior_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-be499835c34b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     ):  \n\u001b[0;32m---> 27\u001b[0;31m         new_x, attn, mask, sigma = self.attention(\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-6ffde2f309cd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, queries, keys, values, attn_mask)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma_projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         out, series, prior, sigma = self.inner_attention(\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-d3bff02371fc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, queries, keys, values, sigma, attn_mask)\u001b[0m\n\u001b[1;32m     61\u001b[0m                     \u001b[0msigma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 ).cuda()\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mprior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mprior\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 314.00 MiB (GPU 0; 39.56 GiB total capacity; 35.97 GiB already allocated; 142.56 MiB free; 37.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nXyaRflgqJ6B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}